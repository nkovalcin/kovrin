"""
Kovrin Schema Exporter

Generates JSON Schema and TypeScript type definitions from Pydantic models.
Detects drift between Python models and existing TypeScript files.

Usage:
    python -m kovrin.schema.exporter --list
    python -m kovrin.schema.exporter --json-schema schemas/
    python -m kovrin.schema.exporter --typescript dashboard/src/types/generated.ts
    python -m kovrin.schema.exporter --validate dashboard/src/types/kovrin.ts
"""

from __future__ import annotations

import argparse
import json
import re
import sys
from enum import Enum
from pathlib import Path
from typing import Any

from pydantic import BaseModel

# ─── All Kovrin Models ───
from kovrin.core.models import (
    AgentDriftMetrics,
    AgentInfo,
    AgentRole,
    ApprovalRequest,
    ApprovalStatus,
    AutonomyProfile,
    AutonomySettings,
    BeamState,
    ConfidenceEstimate,
    ContainmentLevel,
    CounterfactualRequest,
    CounterfactualResult,
    DecompositionCandidate,
    DelegationScope,
    DelegationToken,
    DriftLevel,
    ExecutionResult,
    ExplorationResult,
    MCTSNode,
    ProofObligation,
    PrmScore,
    PrmStepScore,
    ReplayFrame,
    ReplaySession,
    RiskLevel,
    RoutingAction,
    RoutingDecision,
    SpeculationTier,
    SubTask,
    TaskStatus,
    TopologyRecommendation,
    TopologyType,
    Trace,
    ViewMode,
    WatchdogAlert,
)
from kovrin.intent.schema import (
    ExpectedEffect,
    IntentNode,
    IntentV2,
    LanguageGameContext,
    Performative,
    Precondition,
    SemanticFrame,
)


class SchemaExporter:
    """Exports Kovrin Pydantic models as JSON Schema and TypeScript definitions."""

    MODELS: list[type[BaseModel]] = [
        ProofObligation,
        SubTask,
        Trace,
        RoutingDecision,
        ExecutionResult,
        WatchdogAlert,
        ApprovalRequest,
        AgentInfo,
        DecompositionCandidate,
        MCTSNode,
        BeamState,
        ConfidenceEstimate,
        ExplorationResult,
        AutonomySettings,
        ReplayFrame,
        ReplaySession,
        CounterfactualRequest,
        CounterfactualResult,
        PrmStepScore,
        PrmScore,
        AgentDriftMetrics,
        DelegationScope,
        DelegationToken,
        TopologyRecommendation,
        IntentV2,
        IntentNode,
        Precondition,
        ExpectedEffect,
        LanguageGameContext,
    ]

    ENUMS: list[type[Enum]] = [
        RiskLevel,
        TaskStatus,
        SpeculationTier,
        RoutingAction,
        ContainmentLevel,
        AgentRole,
        ApprovalStatus,
        ViewMode,
        AutonomyProfile,
        TopologyType,
        DriftLevel,
        Performative,
        SemanticFrame,
    ]

    # ─── JSON Schema ───

    def export_json_schemas(self) -> dict[str, dict]:
        """Export all models as JSON Schema (serialization mode)."""
        schemas: dict[str, dict] = {}
        for model in self.MODELS:
            schemas[model.__name__] = model.model_json_schema(mode="serialization")
        return schemas

    def write_json_schemas(self, output_dir: str) -> None:
        """Write individual JSON Schema files to a directory."""
        out = Path(output_dir)
        out.mkdir(parents=True, exist_ok=True)
        schemas = self.export_json_schemas()
        for name, schema in schemas.items():
            (out / f"{name}.json").write_text(json.dumps(schema, indent=2) + "\n")

    # ─── TypeScript ───

    def export_typescript(self) -> str:
        """Generate TypeScript type definitions from all models and enums."""
        lines: list[str] = [
            "// Auto-generated by Kovrin SchemaExporter",
            "// Do not edit manually — regenerate with:",
            "//   python -m kovrin.schema.exporter --typescript <path>",
            "",
        ]

        # Enums as union types
        for enum_cls in self.ENUMS:
            members = " | ".join(f"'{m.value}'" for m in enum_cls)
            lines.append(f"export type {enum_cls.__name__} = {members}")
        lines.append("")

        # Models as interfaces
        for model in self.MODELS:
            schema = model.model_json_schema(mode="serialization")
            lines.append(f"export interface {model.__name__} {{")
            defs = schema.get("$defs", {})
            properties = schema.get("properties", {})
            required = set(schema.get("required", []))
            for prop_name, prop_schema in properties.items():
                ts_type = self._schema_to_ts(prop_schema, defs)
                optional = "" if prop_name in required else "?"
                lines.append(f"  {prop_name}{optional}: {ts_type}")
            lines.append("}")
            lines.append("")

        return "\n".join(lines)

    def write_typescript(self, output_path: str) -> None:
        """Write TypeScript definitions to a file."""
        out = Path(output_path)
        out.parent.mkdir(parents=True, exist_ok=True)
        out.write_text(self.export_typescript())

    # ─── Parity Validation ───

    def validate_parity(self, ts_path: str) -> list[str]:
        """Compare existing TypeScript file against Python models.

        Returns a list of discrepancy descriptions. Empty list = full parity.
        """
        ts_content = Path(ts_path).read_text()
        issues: list[str] = []

        # Extract TS type names and interface names
        ts_types = set(re.findall(r"export\s+type\s+(\w+)", ts_content))
        ts_interfaces = set(re.findall(r"export\s+interface\s+(\w+)", ts_content))

        # Check enums
        for enum_cls in self.ENUMS:
            if enum_cls.__name__ not in ts_types:
                issues.append(f"MISSING_TYPE: {enum_cls.__name__} not in TS file")

        # Check models
        for model in self.MODELS:
            name = model.__name__
            if name not in ts_interfaces:
                issues.append(f"MISSING_INTERFACE: {name} not in TS file")
                continue

            # Extract interface fields from TS
            pattern = rf"export\s+interface\s+{name}\s*\{{([^}}]*)\}}"
            match = re.search(pattern, ts_content, re.DOTALL)
            if not match:
                continue
            ts_block = match.group(1)
            ts_fields = set(re.findall(r"(\w+)\s*[?]?\s*:", ts_block))

            # Get Python fields
            schema = model.model_json_schema(mode="serialization")
            py_fields = set(schema.get("properties", {}).keys())

            missing_in_ts = py_fields - ts_fields
            extra_in_ts = ts_fields - py_fields

            for f in sorted(missing_in_ts):
                issues.append(f"MISSING_FIELD: {name}.{f} not in TS")
            for f in sorted(extra_in_ts):
                issues.append(f"EXTRA_FIELD: {name}.{f} not in Python model")

        return sorted(issues)

    # ─── Internal ───

    def _schema_to_ts(self, schema: dict[str, Any] | bool, defs: dict[str, Any]) -> str:
        """Convert a JSON Schema property to a TypeScript type string."""
        if not isinstance(schema, dict):
            return "unknown"

        # Handle $ref
        if "$ref" in schema:
            ref = schema["$ref"]
            ref_name = ref.split("/")[-1]
            # Check if it's an enum in defs
            ref_schema = defs.get(ref_name, {})
            if "enum" in ref_schema:
                return ref_name
            return ref_name

        # Handle anyOf (e.g., nullable types, union types)
        if "anyOf" in schema:
            types = []
            has_null = False
            for variant in schema["anyOf"]:
                if variant.get("type") == "null":
                    has_null = True
                else:
                    types.append(self._schema_to_ts(variant, defs))
            result = " | ".join(types) if types else "unknown"
            if has_null:
                result += " | null"
            return result

        # Handle enum directly
        if "enum" in schema:
            return " | ".join(f"'{v}'" for v in schema["enum"])

        # Handle const
        if "const" in schema:
            v = schema["const"]
            return f"'{v}'" if isinstance(v, str) else str(v)

        schema_type = schema.get("type")

        # Array
        if schema_type == "array":
            items = schema.get("items", {})
            item_type = self._schema_to_ts(items, defs)
            return f"{item_type}[]"

        # Object with properties
        if schema_type == "object":
            if "properties" in schema:
                inner_fields = []
                props = schema["properties"]
                req = set(schema.get("required", []))
                for k, v in props.items():
                    opt = "" if k in req else "?"
                    inner_fields.append(f"{k}{opt}: {self._schema_to_ts(v, defs)}")
                return "{ " + "; ".join(inner_fields) + " }"
            # additionalProperties (Record type)
            add_props = schema.get("additionalProperties")
            if add_props:
                val_type = self._schema_to_ts(add_props, defs)
                return f"Record<string, {val_type}>"
            return "Record<string, unknown>"

        # Primitives
        type_map = {
            "string": "string",
            "integer": "number",
            "number": "number",
            "boolean": "boolean",
            "null": "null",
        }
        if schema_type in type_map:
            return type_map[schema_type]

        return "unknown"


# ─── CLI ───

def main() -> None:
    parser = argparse.ArgumentParser(
        prog="kovrin.schema.exporter",
        description="Export Kovrin Pydantic models as JSON Schema or TypeScript",
    )
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument("--list", action="store_true", help="List all exportable models and enums")
    group.add_argument("--json-schema", metavar="DIR", help="Write JSON Schema files to directory")
    group.add_argument("--typescript", metavar="FILE", help="Write TypeScript definitions to file")
    group.add_argument("--validate", metavar="FILE", help="Validate parity with existing TS file")

    args = parser.parse_args()
    exporter = SchemaExporter()

    if args.list:
        print("Models:")
        for m in exporter.MODELS:
            fields = list(m.model_json_schema(mode="serialization").get("properties", {}).keys())
            print(f"  {m.__name__:30s} ({len(fields)} fields)")
        print(f"\nEnums:")
        for e in exporter.ENUMS:
            print(f"  {e.__name__:30s} ({len(e)} members)")
        print(f"\nTotal: {len(exporter.MODELS)} models, {len(exporter.ENUMS)} enums")

    elif args.json_schema:
        exporter.write_json_schemas(args.json_schema)
        schemas = exporter.export_json_schemas()
        print(f"Wrote {len(schemas)} JSON Schema files to {args.json_schema}/")

    elif args.typescript:
        exporter.write_typescript(args.typescript)
        print(f"Wrote TypeScript definitions to {args.typescript}")

    elif args.validate:
        issues = exporter.validate_parity(args.validate)
        if issues:
            print(f"Found {len(issues)} discrepancies:")
            for issue in issues:
                print(f"  {issue}")
            sys.exit(1)
        else:
            print("Full parity — no discrepancies found.")


if __name__ == "__main__":
    main()
